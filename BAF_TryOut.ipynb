{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFN9fiZ6uZ3eY+tqbkXUEF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDankloff/Delayed-Fairness-Project/blob/main/BAF_TryOut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "NPDu2yHvtDmy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1T2_vWO8s0tU"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import glob\n",
        "import os\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aequitas #fairness tree\n",
        "from aequitas.group import Group # Fairness metrics"
      ],
      "metadata": {
        "id": "MQ4-2dXUt9ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load BAF data"
      ],
      "metadata": {
        "id": "oXmaS-13tIHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saved parquet files from csv"
      ],
      "metadata": {
        "id": "Z09Zv6t2uuJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cd '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxvmYW9wtNse",
        "outputId": "8acaef61-df68-414e-cbde-119c52382df7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/parquet data'\n",
        "\n",
        "extension = \"parquet\" #parquet for smaller files, csv available\n",
        "data_paths = glob.glob(f\"{base_path}/*.{extension}\")\n",
        "\n",
        "def read_dataset(path, ext = extension):\n",
        "    if ext == \"csv\":\n",
        "      return pd.read_csv(path)\n",
        "    elif ext == \"parquet\":\n",
        "      return pd.read_parquet(path)\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "# Extract variant name from the file path (without the extension)\n",
        "def get_variant(path):\n",
        "    return os.path.basename(path).split(\".\")[0]\n",
        "\n",
        "# Dictionary comprehension to read all CSV files into a dictionary of DataFrames\n",
        "dataframes = {\n",
        "    get_variant(path): read_dataset(path) for path in data_paths\n",
        "}\n",
        "print(f\"Loaded datasets: {list(dataframes.keys())}\")\n",
        "\n",
        "datasets_paths = {\n",
        "    \"Base\": base_path + \"/Base.parquet\", # sampled to best represent original dataset\n",
        "    \"Variant I\": base_path + \"/Variant I.parquet\", # higher group size disparity than base - reducing the size of the minority group from approx 20 - 10% of the dataset\n",
        "    \"Variant II\": base_path + \"/Variant II.parquet\", # higher prevalence disparity than base - one group has 5 x the fraud detection rate of the other while group sizes are equal\n",
        "    \"Variant III\": base_path + \"/Variant III.parquet\", # better separability for one of the groups -\n",
        "    \"Variant IV\": base_path + \"/Variant IV.parquet\", # higher prevalence disparity in train\n",
        "    \"Variant V\": base_path + \"/Variant V.parquet\", # better separability in train for one of the groups\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW0cdNzIu46h",
        "outputId": "121c5540-9b44-4de3-9764-f40faa71a128"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded datasets: ['Base', 'Variant I', 'Variant II', 'Variant III', 'Variant IV', 'Variant V']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename datasets\n",
        "base = dataframes['Base']\n",
        "variant1 = dataframes['Variant I']\n",
        "variant2 = dataframes['Variant II']\n",
        "variant3 = dataframes['Variant III']\n",
        "variant4 = dataframes['Variant IV']\n",
        "variant5 = dataframes['Variant V']\n",
        "\n",
        "#for better display\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.max_rows', 50)\n",
        "\n",
        "dfs = [base, variant1, variant2, variant3, variant4, variant5]\n",
        "\n",
        "df = variant1 #set to preferred variant\n",
        "new_df = df.copy()\n",
        "# Get the number of unique values in each column of the DataFrame\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cMSCJxnvbR2",
        "outputId": "64a0cc0b-e437-485b-b3d2-ec163b2db207"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 32 columns):\n",
            " #   Column                            Non-Null Count    Dtype  \n",
            "---  ------                            --------------    -----  \n",
            " 0   fraud_bool                        1000000 non-null  int64  \n",
            " 1   income                            1000000 non-null  float64\n",
            " 2   name_email_similarity             1000000 non-null  float64\n",
            " 3   prev_address_months_count         1000000 non-null  int64  \n",
            " 4   current_address_months_count      1000000 non-null  int64  \n",
            " 5   customer_age                      1000000 non-null  int64  \n",
            " 6   days_since_request                1000000 non-null  float64\n",
            " 7   intended_balcon_amount            1000000 non-null  float64\n",
            " 8   payment_type                      1000000 non-null  object \n",
            " 9   zip_count_4w                      1000000 non-null  int64  \n",
            " 10  velocity_6h                       1000000 non-null  float64\n",
            " 11  velocity_24h                      1000000 non-null  float64\n",
            " 12  velocity_4w                       1000000 non-null  float64\n",
            " 13  bank_branch_count_8w              1000000 non-null  int64  \n",
            " 14  date_of_birth_distinct_emails_4w  1000000 non-null  int64  \n",
            " 15  employment_status                 1000000 non-null  object \n",
            " 16  credit_risk_score                 1000000 non-null  int64  \n",
            " 17  email_is_free                     1000000 non-null  int64  \n",
            " 18  housing_status                    1000000 non-null  object \n",
            " 19  phone_home_valid                  1000000 non-null  int64  \n",
            " 20  phone_mobile_valid                1000000 non-null  int64  \n",
            " 21  bank_months_count                 1000000 non-null  int64  \n",
            " 22  has_other_cards                   1000000 non-null  int64  \n",
            " 23  proposed_credit_limit             1000000 non-null  float64\n",
            " 24  foreign_request                   1000000 non-null  int64  \n",
            " 25  source                            1000000 non-null  object \n",
            " 26  session_length_in_minutes         1000000 non-null  float64\n",
            " 27  device_os                         1000000 non-null  object \n",
            " 28  keep_alive_session                1000000 non-null  int64  \n",
            " 29  device_distinct_emails_8w         1000000 non-null  int64  \n",
            " 30  device_fraud_count                1000000 non-null  int64  \n",
            " 31  month                             1000000 non-null  int64  \n",
            "dtypes: float64(9), int64(18), object(5)\n",
            "memory usage: 244.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore Data"
      ],
      "metadata": {
        "id": "IJTZcm81xR7a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HtWExZyfxVQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulate"
      ],
      "metadata": {
        "id": "pGzPaYWmxNyt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pt-G4EZXxPhH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}