{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7666e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append('../src')\n",
    "\n",
    "from evaluation import *\n",
    "from taiwan_generator import *\n",
    "from fair_model import FairModel\n",
    "from utils import gen_plot_data, plot_data, combine_tuples\n",
    "from baselines import LR, CvxFairModel, EOFairModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745fb831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taiwan_generator reloaded.\n"
     ]
    }
   ],
   "source": [
    "# Reload taiwan_generator to pick up latest source changes\n",
    "import sys, importlib\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "import taiwan_generator\n",
    "importlib.reload(taiwan_generator)\n",
    "from taiwan_generator import *\n",
    "print(\"taiwan_generator reloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af651c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "S, X, Y, PARAMS = preprocess_data()\n",
    "(s_train, X_train, y_train), (s_test, X_test, y_test) = split_data(S, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2930eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Bank model\n",
    "bank = Bank(params=PARAMS)\n",
    "agent_train = Agent(s_train, X_train, y_train, eps=0.1, base=[0.0, 0.1], seed=2021)\n",
    "agent_test = Agent(s_test, X_test, y_test, eps=0.1, base=[0.0, 0.1], seed=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f316945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets\n",
    "s_train, Xs_train, Ys_train = gen_multi_step_profiles(bank, agent_train, steps=4)\n",
    "s_test, Xs_test, Ys_test = gen_multi_step_profiles(bank, agent_test, steps=4)\n",
    "s_comb, X_comb, Y_comb = combine_tuples(s_train, Xs_train, Ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49706c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " step   i   s       x0       x1                 y\n",
      "    0 1.0 0.0 0.538964 0.069038               0.0\n",
      "    0 2.0 0.0 2.467062 1.878806               1.0\n",
      "    1 1.0 0.0 0.538964 0.069038               0.0\n",
      "    1 2.0 0.0 2.478389 1.889695               1.0\n",
      "    2 1.0 0.0 0.538964 0.069038               0.0\n",
      "    2 2.0 0.0 2.489734 1.900600               1.0\n",
      "    3 1.0 0.0 0.538964 0.069038               0.0\n",
      "    3 2.0 0.0 2.501096 1.911522               1.0\n",
      "    4 NaN NaN      NaN      NaN step out of range\n"
     ]
    }
   ],
   "source": [
    "# Print s, all X columns, y for steps 0..4 at i=1 and i=2\n",
    "import numpy as np\n",
    "\n",
    "# Compute per-step sizes and cumulative boundaries from Xs_train\n",
    "step_sizes = [len(x_step) for x_step in Xs_train]\n",
    "cum = np.cumsum([0] + step_sizes)\n",
    "\n",
    "steps_to_show = [0, 1, 2, 3, 4]\n",
    "indices_to_show = [1, 2]\n",
    "\n",
    "rows = []\n",
    "for t in steps_to_show:\n",
    "    if t < 0 or t >= len(step_sizes):\n",
    "        rows.append((t, None, None, None, \"step out of range\"))\n",
    "        continue\n",
    "    for i in indices_to_show:\n",
    "        if i < 0 or i >= step_sizes[t]:\n",
    "            rows.append((t, i, None, None, \"i out of range for this step\"))\n",
    "            continue\n",
    "        gi = cum[t] + i  # global index in combined arrays\n",
    "        s_val = float(s_comb[gi])\n",
    "        x_vals = X_comb[gi]\n",
    "        y_val = float(Y_comb[gi])\n",
    "        rows.append((t, i, s_val, x_vals, y_val))\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    # Expand x_vals into separate columns x0..x{d-1}\n",
    "    max_d = X_comb.shape[1]\n",
    "    def to_row(r):\n",
    "        t, i, s_val, x_vals, y_val = r\n",
    "        if x_vals is None:\n",
    "            return {\"step\": t, \"i\": i, \"s\": s_val, **{f\"x{j}\": None for j in range(max_d)}, \"y\": y_val}\n",
    "        return {\"step\": t, \"i\": i, \"s\": s_val, **{f\"x{j}\": float(x_vals[j]) for j in range(max_d)}, \"y\": y_val}\n",
    "    out_df = pd.DataFrame([to_row(r) for r in rows])\n",
    "    print(out_df.to_string(index=False))\n",
    "except Exception:\n",
    "    for r in rows:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae73d5",
   "metadata": {},
   "source": [
    "### Baseline: LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Step 1 - Logistic Regression ------------------------------\n",
      "Acc: 82.8%\n",
      "Short Fairness: 0.015\n",
      "Long fairness: 0.038\n",
      "------------------------------ Step 2 - Logistic Regression ------------------------------\n",
      "Acc: 82.6%\n",
      "Short Fairness: 0.018\n",
      "Long fairness: 0.088\n",
      "------------------------------ Step 3 - Logistic Regression ------------------------------\n",
      "Acc: 84.1%\n",
      "Short Fairness: 0.021\n",
      "Long fairness: 0.243\n",
      "------------------------------ Step 4 - Logistic Regression ------------------------------\n",
      "Acc: 81.6%\n",
      "Short Fairness: 0.012\n",
      "Long fairness: 0.433\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LR(l2_reg=1e-5)\n",
    "lr.train(s_comb, X_comb, Y_comb)\n",
    "\n",
    "_, Xs_te, Ys_te = gen_multi_step_profiles(lr, agent_test, steps=4)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, lr, OYs=OYs_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f617ab",
   "metadata": {},
   "source": [
    "### Baseline: FMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f152bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n",
      "------------------------------ Step 1 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 83.0%\n",
      "Short Fairness: 0.063\n",
      "Long fairness: 0.038\n",
      "------------------------------ Step 2 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 84.3%\n",
      "Short Fairness: 0.066\n",
      "Long fairness: 0.076\n",
      "------------------------------ Step 3 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 84.6%\n",
      "Short Fairness: 0.075\n",
      "Long fairness: 0.223\n",
      "------------------------------ Step 4 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 84.1%\n",
      "Short Fairness: 0.069\n",
      "Long fairness: 0.397\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfm = CvxFairModel(n_features=len(Xs_train[0][0])+2, l2_reg=1e-5, tao=1.6)\n",
    "cfm.train(s_comb, X_comb, Y_comb)\n",
    "\n",
    "_, Xs_te, Ys_te = gen_multi_step_profiles(cfm, agent_test, steps=4)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, cfm, OYs=OYs_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f856ada",
   "metadata": {},
   "source": [
    "### Baseline: FMEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ba1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n",
      "------------------------------ Step 1 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 82.4%\n",
      "Short Fairness: 0.072\n",
      "Long fairness: 0.006\n",
      "------------------------------ Step 2 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 83.0%\n",
      "Short Fairness: 0.075\n",
      "Long fairness: 0.045\n",
      "------------------------------ Step 3 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 83.0%\n",
      "Short Fairness: 0.087\n",
      "Long fairness: 0.156\n",
      "------------------------------ Step 4 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 81.3%\n",
      "Short Fairness: 0.078\n",
      "Long fairness: 0.295\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqm = EOFairModel(n_features=len(Xs_train[0][0])+2, l2_reg=1e-5, tao=1.67)\n",
    "eqm.train(s_comb, X_comb, Y_comb)\n",
    "\n",
    "_, Xs_te, Ys_te = gen_multi_step_profiles(eqm, agent_test, steps=4)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, eqm, OYs=OYs_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e72c2d",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa1a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Done!\n"
     ]
    }
   ],
   "source": [
    "fm = FairModel(n_features=len(Xs_train[0][0])+1, lr=5e-3, l2_reg=1e-5, sf_reg=0.0223, lf_reg=0.715)\n",
    "fm.train(s_train, Xs_train, Ys_train, Xs_train, Ys_train, epochs=1000, plot=False, short_type='neg')\n",
    "\n",
    "num_iters = 30\n",
    "theta_true = fm.params\n",
    "theta_list     = [np.copy(theta_true)]\n",
    "theta_gaps     = []\n",
    "\n",
    "# inital theta\n",
    "theta = np.copy(theta_true)\n",
    "for t in range(num_iters):\n",
    "    # adjust distribution to current theta\n",
    "    _, NXs_train, NYs_train = gen_multi_step_profiles(fm, agent_train, steps=4)\n",
    "    # learn on induced distribution\n",
    "    fm.train(s_train, Xs_train, Ys_train, NXs_train, NYs_train, epochs=10, plot=False, short_type='neg')\n",
    "    \n",
    "    # keep track of statistic\n",
    "    theta_new = fm.params\n",
    "    theta_gaps.append(np.linalg.norm(theta_new - theta))\n",
    "    theta_list.append(np.copy(theta_new))\n",
    "\n",
    "    theta = np.copy(theta_new)\n",
    "print(\"Retraining Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76dd2605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Step 1 - Long-term Fair Model ------------------------------\n",
      "Acc: 68.4%\n",
      "Short Fairness: 0.176\n",
      "Long fairness: 0.018\n",
      "------------------------------ Step 2 - Long-term Fair Model ------------------------------\n",
      "Acc: 65.6%\n",
      "Short Fairness: 0.176\n",
      "Long fairness: 0.029\n",
      "------------------------------ Step 3 - Long-term Fair Model ------------------------------\n",
      "Acc: 65.4%\n",
      "Short Fairness: 0.174\n",
      "Long fairness: 0.034\n",
      "------------------------------ Step 4 - Long-term Fair Model ------------------------------\n",
      "Acc: 69.5%\n",
      "Short Fairness: 0.174\n",
      "Long fairness: 0.073\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, Xs_te, Ys_te = gen_multi_step_profiles(fm, agent_test, steps=4)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, fm, OYs=OYs_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect original dataset columns and map x0/x1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load original Excel file (same path used in read_taiwan_data)\n",
    "file_path = \"../data/default of credit card clients.xls\"\n",
    "df_raw = pd.read_excel(file_path, header=1)\n",
    "\n",
    "# Apply the same filtering as read_taiwan_data\n",
    "mask = (df_raw['PAY_AMT1'] < 10000) & (df_raw['PAY_AMT1'] > 10)\n",
    "mask &= (df_raw['PAY_AMT2'] < 10000) & (df_raw['PAY_AMT2'] > 10)\n",
    "df_f = df_raw.loc[mask].copy()\n",
    "\n",
    "# Balanced sampling by label/group, same as generator\n",
    "label0 = df_f[(df_f['default payment next month'] == 1) & (df_f['SEX'] == 1)].sample(n=1000, replace=False, random_state=2021)\n",
    "label1 = df_f[(df_f['default payment next month'] == 0) & (df_f['SEX'] == 1)].sample(n=1000, replace=False, random_state=2021)\n",
    "label2 = df_f[(df_f['default payment next month'] == 1) & (df_f['SEX'] == 2)].sample(n=1000, replace=False, random_state=2021)\n",
    "label3 = df_f[(df_f['default payment next month'] == 0) & (df_f['SEX'] == 2)].sample(n=1000, replace=False, random_state=2021)\n",
    "df_f = pd.concat([label0, label1, label2, label3], axis=0)\n",
    "\n",
    "# Identify the exact column names for iloc[:, 18:20]\n",
    "all_cols = list(df_f.columns)\n",
    "selected_cols = all_cols[18:20]\n",
    "print(\"Selected feature columns (iloc[:, 18:20]):\", selected_cols)\n",
    "\n",
    "# Construct S, X, Y exactly like read_taiwan_data\n",
    "X_raw = df_f.iloc[:, 18:20].copy()\n",
    "X_scaled = X_raw.apply(lambda x: 3 * (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "S_vec = df_f['SEX'] - 1\n",
    "Y_vec = df_f['default payment next month'].replace({0:1, 1:0})\n",
    "\n",
    "# Show first 5 rows mapping\n",
    "out = pd.DataFrame({\n",
    "    's': S_vec.head(5).astype(int),\n",
    "    'x0_raw': X_raw.iloc[:5, 0].values,\n",
    "    'x1_raw': X_raw.iloc[:5, 1].values,\n",
    "    'x0': X_scaled.iloc[:5, 0].values,\n",
    "    'x1': X_scaled.iloc[:5, 1].values,\n",
    "    'y': Y_vec.head(5).astype(int)\n",
    "})\n",
    "print(\"Sample mapping (first 5 rows):\")\n",
    "print(out.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small multi-step simulation: show s, x0, x1, y across steps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use already built bank and agent_test if available; else rebuild quickly\n",
    "try:\n",
    "    bank\n",
    "    agent_test\n",
    "except NameError:\n",
    "    S_sim, X_sim, Y_sim, PARAMS_sim = preprocess_data()\n",
    "    (_, X_train_sim, y_train_sim), (s_test, X_test, y_test) = split_data(S_sim, X_sim, Y_sim)\n",
    "    bank = Bank(params=PARAMS_sim)\n",
    "    agent_test = Agent(s_test, X_test, y_test, eps=0.1, base=[0.0, 0.1], seed=2020)\n",
    "\n",
    "# Generate a short trajectory (5 steps)\n",
    "s_test_sim, Xs_test_sim, Ys_test_sim = gen_multi_step_profiles(bank, agent_test, steps=5)\n",
    "\n",
    "# Pick a few indices to track\n",
    "indices = [0, 1, 2]\n",
    "rows = []\n",
    "for t in range(len(Xs_test_sim)):\n",
    "    X_step = Xs_test_sim[t]\n",
    "    Y_step = Ys_test_sim[t]\n",
    "    for i in indices:\n",
    "        if i >= len(X_step):\n",
    "            continue\n",
    "        s_val = float(s_test_sim[i])\n",
    "        x0, x1 = float(X_step[i][0]), float(X_step[i][1])\n",
    "        y_val = float(Y_step[i])\n",
    "        rows.append({\"step\": t, \"i\": i, \"s\": s_val, \"x0\": x0, \"x1\": x1, \"y\": y_val})\n",
    "\n",
    "print(pd.DataFrame(rows).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
