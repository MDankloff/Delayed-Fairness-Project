{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a91878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append('../src')\n",
    "\n",
    "from generator import *\n",
    "from evaluation import *\n",
    "from fair_model import FairModel\n",
    "from baselines import LR, CvxFairModel, EOFairModel\n",
    "from utils import gen_plot_data, plot_axes, combine_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2935e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Bank model\n",
    "bank = Bank()\n",
    "agent_train = Agent(n_samples=4000, protect_ratio=0.5, eps=0.5, base=[0.2, 1.0], seed=2021)\n",
    "agent_test = Agent(n_samples=1000, protect_ratio=0.5, eps=0.5, base=[0.2, 1.0], seed=2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e96b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator.Agent object at 0x3291d36d0>\n"
     ]
    }
   ],
   "source": [
    "print(agent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ececb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets\n",
    "s_train, Xs_train, Ys_train = gen_multi_step_profiles(bank, agent_train, steps=5)\n",
    "s_test, Xs_test, Ys_test = gen_multi_step_profiles(bank, agent_test, steps=5)\n",
    "s_comb, X_comb, Y_comb = combine_tuples(s_train, Xs_train, Ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab18ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " step  i  comb_idx   s        x0        x1   y\n",
      "    0  0         0 0.0 -0.430098  0.281743 0.0\n",
      "    0  1         1 1.0 -2.560764  1.697506 0.0\n",
      "    0  2         2 0.0 -2.026388 -4.358015 1.0\n",
      "    0  3         3 1.0  0.031396  2.650109 0.0\n",
      "    0  4         4 1.0  4.189555  3.041892 1.0\n",
      "    0  5         5 0.0 -0.607038 -5.042286 0.0\n",
      "    0  6         6 0.0 -5.328782  0.289171 0.0\n",
      "    0  7         7 0.0 -5.758294 -3.710050 0.0\n",
      "    0  8         8 0.0 -4.338420 -0.032810 0.0\n",
      "    0  9         9 0.0 -1.432677 -3.118676 0.0\n"
     ]
    }
   ],
   "source": [
    "# Preview the first 10 rows with time step mapping\n",
    "# We reconstruct (step, sample index) from the structure of s_train/Xs_train/Ys_train and how combine_tuples flattens them.\n",
    "# Assumes combine_tuples concatenates steps along rows in order: step 0, step 1, ...\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    # Build the combined data frame as before\n",
    "    data = np.hstack([s_comb.reshape(-1, 1), X_comb, Y_comb.reshape(-1, 1)])\n",
    "    base_columns = [\"s\"] + [f\"x{i}\" for i in range(X_comb.shape[1])] + [\"y\"]\n",
    "    df = pd.DataFrame(data, columns=base_columns)\n",
    "\n",
    "    # Infer per-step sizes from the original lists (Xs_train/Ys_train)\n",
    "    # Each Xs_train[t] is (n_t, d); we accumulate to compute global row indices per step.\n",
    "    step_sizes = [len(x_step) for x_step in Xs_train]\n",
    "    cum = np.cumsum([0] + step_sizes)  # boundaries\n",
    "\n",
    "    # Create arrays for (step, i-in-step)\n",
    "    idx = np.arange(len(df))\n",
    "    # Find step for each global index using cumulative boundaries\n",
    "    step = np.searchsorted(cum[1:], idx, side=\"right\")\n",
    "    i_in_step = idx - cum[step]\n",
    "\n",
    "    df.insert(0, \"step\", step)\n",
    "    df.insert(1, \"i\", i_in_step)\n",
    "    df.insert(2, \"comb_idx\", idx)\n",
    "\n",
    "    # Show first 10 rows with mapping columns\n",
    "    print(df.head(10).to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(\"Failed to annotate with step/index due to:\", e)\n",
    "    # Fallback to the simple 10-row preview\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        data = np.hstack([s_comb.reshape(-1, 1), X_comb, Y_comb.reshape(-1, 1)])\n",
    "        columns = [\"s\"] + [f\"x{i}\" for i in range(X_comb.shape[1])] + [\"y\"]\n",
    "        df_preview = pd.DataFrame(data, columns=columns)\n",
    "        print(df_preview.head(10).to_string(index=False))\n",
    "    except Exception as e2:\n",
    "        print(\"pandas not available (\", e2, \") â€” showing raw arrays instead:\\n\")\n",
    "        print(\"s:\\n\", s_comb[:10])\n",
    "        print(\"\\nX:\\n\", X_comb[:10])\n",
    "        print(\"\\ny:\\n\", Y_comb[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202d4b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " step   i   s        x0        x1   y              note\n",
      "    0 1.0 1.0 -2.560764  1.697506 0.0                  \n",
      "    0 2.0 0.0 -2.026388 -4.358015 1.0                  \n",
      "    1 1.0 1.0 -1.560764  2.697506 0.0                  \n",
      "    1 2.0 0.0 -2.052291 -4.045064 1.0                  \n",
      "    2 1.0 1.0 -0.560764  3.697506 0.0                  \n",
      "    2 2.0 0.0 -1.852291 -3.845064 1.0                  \n",
      "    3 1.0 1.0  0.439236  4.697506 0.0                  \n",
      "    3 2.0 0.0 -1.435847 -3.753286 0.0                  \n",
      "    4 1.0 1.0  1.439236  5.697506 1.0                  \n",
      "    4 2.0 0.0 -1.497099 -3.422660 0.0                  \n",
      "    5 NaN NaN       NaN       NaN NaN step out of range\n"
     ]
    }
   ],
   "source": [
    "# Print s, x0, x1, y for steps 0..5 at i=1 and i=2\n",
    "import numpy as np\n",
    "\n",
    "# Derive per-step sizes and cumulative boundaries from Xs_train\n",
    "step_sizes = [len(x_step) for x_step in Xs_train]\n",
    "cum = np.cumsum([0] + step_sizes)\n",
    "\n",
    "steps_to_show = [0, 1, 2, 3, 4, 5]\n",
    "indices_to_show = [1, 2]\n",
    "\n",
    "rows = []\n",
    "for t in steps_to_show:\n",
    "    if t < 0 or t >= len(step_sizes):\n",
    "        rows.append((t, None, None, None, None, None, \"step out of range\"))\n",
    "        continue\n",
    "    for i in indices_to_show:\n",
    "        if i < 0 or i >= step_sizes[t]:\n",
    "            rows.append((t, i, None, None, None, None, \"i out of range for this step\"))\n",
    "            continue\n",
    "        gi = cum[t] + i  # global index in combined arrays\n",
    "        s_val = float(s_comb[gi])\n",
    "        x0 = float(X_comb[gi, 0])\n",
    "        x1 = float(X_comb[gi, 1])\n",
    "        y_val = float(Y_comb[gi])\n",
    "        rows.append((t, i, s_val, x0, x1, y_val, \"\"))\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    out_df = pd.DataFrame(rows, columns=[\"step\", \"i\", \"s\", \"x0\", \"x1\", \"y\", \"note\"])\n",
    "    print(out_df.to_string(index=False))\n",
    "except Exception:\n",
    "    for r in rows:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29224b08",
   "metadata": {},
   "source": [
    "### Baseline: LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949e7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Step 1 - Logistic Regression ------------------------------\n",
      "Acc: 91.2%\n",
      "Short Fairness: 0.152\n",
      "Long fairness: 0.058\n",
      "------------------------------ Step 2 - Logistic Regression ------------------------------\n",
      "Acc: 89.4%\n",
      "Short Fairness: 0.160\n",
      "Long fairness: 0.117\n",
      "------------------------------ Step 3 - Logistic Regression ------------------------------\n",
      "Acc: 91.7%\n",
      "Short Fairness: 0.166\n",
      "Long fairness: 0.173\n",
      "------------------------------ Step 4 - Logistic Regression ------------------------------\n",
      "Acc: 92.1%\n",
      "Short Fairness: 0.164\n",
      "Long fairness: 0.246\n",
      "------------------------------ Step 5 - Logistic Regression ------------------------------\n",
      "Acc: 91.7%\n",
      "Short Fairness: 0.174\n",
      "Long fairness: 0.340\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LR(l2_reg=1e-5)\n",
    "lr.train(s_comb, X_comb, Y_comb)\n",
    "\n",
    "_, Xs_te, Ys_te = gen_multi_step_profiles(lr, agent_test, steps=5)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, lr, OYs=OYs_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c55e0f",
   "metadata": {},
   "source": [
    "### Baseline: FMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ad1725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Step 1 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 35.2%\n",
      "Short Fairness: 0.024\n",
      "Long fairness: 0.002\n",
      "------------------------------ Step 2 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 41.7%\n",
      "Short Fairness: 0.022\n",
      "Long fairness: 0.002\n",
      "------------------------------ Step 3 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 45.2%\n",
      "Short Fairness: 0.020\n",
      "Long fairness: 0.002\n",
      "------------------------------ Step 4 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 49.3%\n",
      "Short Fairness: 0.020\n",
      "Long fairness: 0.002\n",
      "------------------------------ Step 5 - Fair Model with Demographic Parity ------------------------------\n",
      "Acc: 53.3%\n",
      "Short Fairness: 0.022\n",
      "Long fairness: 0.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = X_comb.shape[1]            # number of X columns\n",
    "cfm = CvxFairModel(n_features=d + 1, l2_reg=1e-5, tao=1.565)  # s + X\n",
    "\n",
    "# cfm = CvxFairModel(n_features=len(Xs_train[0][0])+2, l2_reg=1e-5, tao=1.565)\n",
    "\n",
    "cfm.train(s_comb, X_comb, Y_comb)\n",
    "\n",
    "_, Xs_te, Ys_te = gen_multi_step_profiles(cfm, agent_test, steps=5)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, cfm, OYs=OYs_te) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a5db6",
   "metadata": {},
   "source": [
    "## Baseline: FMEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0d59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n",
      "------------------------------ Step 1 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 82.9%\n",
      "Short Fairness: 0.010\n",
      "Long fairness: 0.080\n",
      "------------------------------ Step 2 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 79.0%\n",
      "Short Fairness: 0.010\n",
      "Long fairness: 0.122\n",
      "------------------------------ Step 3 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 79.5%\n",
      "Short Fairness: 0.010\n",
      "Long fairness: 0.190\n",
      "------------------------------ Step 4 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 80.0%\n",
      "Short Fairness: 0.014\n",
      "Long fairness: 0.276\n",
      "------------------------------ Step 5 - Fair Model with Equal Oppertunity ------------------------------\n",
      "Acc: 81.4%\n",
      "Short Fairness: 0.020\n",
      "Long fairness: 0.352\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqm = EOFairModel(n_features=len(Xs_train[0][0])+2, l2_reg=1e-5, tao=1.5)\n",
    "eqm.train(s_comb, X_comb, Y_comb)\n",
    "\n",
    "_, Xs_te, Ys_te = gen_multi_step_profiles(eqm, agent_test, steps=5)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, eqm, OYs=OYs_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047c1f3",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b344cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Done!\n"
     ]
    }
   ],
   "source": [
    "fm = FairModel(n_features=len(Xs_train[0][0])+1, lr=5e-3, l2_reg=1e-5, sf_reg=0.119, lf_reg=0.154)\n",
    "fm.train(s_train, Xs_train, Ys_train, Xs_train, Ys_train, epochs=1000, plot=False)\n",
    "\n",
    "num_iters = 50\n",
    "\n",
    "theta_true = fm.params\n",
    "theta_list     = [np.copy(theta_true)]\n",
    "theta_gaps     = []\n",
    "\n",
    "\n",
    "# inital theta\n",
    "theta = np.copy(theta_true)\n",
    "\n",
    "for t in range(num_iters):\n",
    "    # adjust distribution to current theta\n",
    "    _, NXs_train, NYs_train = gen_multi_step_profiles(fm, agent_train, steps=5)\n",
    "    # learn on induced distribution\n",
    "    fm.train(s_train, Xs_train, Ys_train, NXs_train, NYs_train, epochs=10, plot=False)\n",
    "    \n",
    "    # keep track of statistic\n",
    "    theta_new = fm.params\n",
    "    theta_gaps.append(np.linalg.norm(theta_new - theta))\n",
    "    theta_list.append(np.copy(theta_new))\n",
    "\n",
    "    theta = np.copy(theta_new)\n",
    "print(\"Retraining Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb056d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved params to: /Users/jh22215/Documents/GitHub/Delayed-Fairness-Project/Synthetic/exp/checkpoints/fairmodel_params.npz\n",
      "Saved state_dict to: /Users/jh22215/Documents/GitHub/Delayed-Fairness-Project/Synthetic/exp/checkpoints/fairmodel_state_dict.pt\n",
      "theta shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "# Save trained parameters to disk (portable: NumPy .npz)\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "ckpt_dir = Path(\"checkpoints\")\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "params_path = ckpt_dir / \"fairmodel_params.npz\"\n",
    "state_path  = ckpt_dir / \"fairmodel_state_dict.pt\"\n",
    "\n",
    "theta = np.asarray(fm.params, dtype=np.float32)  # shape: (n_features + 1,)\n",
    "\n",
    "np.savez(\n",
    "    params_path,\n",
    "    params=theta,\n",
    "    n_features=int(fm.linear.weight.shape[1]),\n",
    ")\n",
    "\n",
    "# Optional: save full torch state_dict too (lets you restore optimizer, etc. if you want later)\n",
    "torch.save(fm.state_dict(), state_path)\n",
    "\n",
    "print(f\"Saved params to: {params_path.resolve()}\")\n",
    "print(f\"Saved state_dict to: {state_path.resolve()}\")\n",
    "print(\"theta shape:\", theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12140c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded theta OK. First 5 entries: [-0.01447977  0.08411454 -0.07414891 -0.14454328]\n",
      "Params match: True\n"
     ]
    }
   ],
   "source": [
    "# Load parameters somewhere else and apply to a fresh FairModel\n",
    "# (Works even in a different notebook/script, as long as you have the same n_features)\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def load_params_npz(npz_path):\n",
    "    npz_path = Path(npz_path)\n",
    "    data = np.load(npz_path)\n",
    "    return np.asarray(data[\"params\"], dtype=np.float32)\n",
    "\n",
    "\n",
    "def apply_theta_to_fairmodel(model: FairModel, theta: np.ndarray) -> None:\n",
    "    \"\"\"theta is [w0, w1, ..., w_{d-1}, b] matching FairModel.params.\"\"\"\n",
    "    theta = np.asarray(theta, dtype=np.float32).ravel()\n",
    "    d = int(model.linear.weight.shape[1])\n",
    "    if theta.shape[0] != d + 1:\n",
    "        raise ValueError(f\"theta has len {theta.shape[0]} but expected {d + 1} (d={d})\")\n",
    "\n",
    "    w = torch.from_numpy(theta[:d]).view(1, d)\n",
    "    b = torch.tensor([float(theta[-1])], dtype=w.dtype)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.linear.weight.copy_(w)\n",
    "        model.linear.bias.copy_(b)\n",
    "\n",
    "    # keep old_* in sync with the loaded weights\n",
    "    model.save_params()\n",
    "\n",
    "\n",
    "params_path = Path(\"checkpoints\") / \"fairmodel_params.npz\"\n",
    "loaded_theta = load_params_npz(params_path)\n",
    "\n",
    "# Example: create a new model with the same n_features and load the theta\n",
    "fm_loaded = FairModel(\n",
    "    n_features=int(fm.linear.weight.shape[1]),\n",
    "    lr=5e-3,\n",
    "    l2_reg=1e-5,\n",
    "    sf_reg=0.119,\n",
    "    lf_reg=0.154,\n",
    ")\n",
    "apply_theta_to_fairmodel(fm_loaded, loaded_theta)\n",
    "\n",
    "print(\"Loaded theta OK. First 5 entries:\", loaded_theta[:5])\n",
    "print(\"Params match:\", np.allclose(fm_loaded.params, loaded_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ede5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Step 1 - Long-term Fair Model ------------------------------\n",
      "Acc: 80.0%\n",
      "Short Fairness: 0.016\n",
      "Long fairness: 0.034\n",
      "------------------------------ Step 2 - Long-term Fair Model ------------------------------\n",
      "Acc: 74.9%\n",
      "Short Fairness: 0.018\n",
      "Long fairness: 0.026\n",
      "------------------------------ Step 3 - Long-term Fair Model ------------------------------\n",
      "Acc: 72.8%\n",
      "Short Fairness: 0.018\n",
      "Long fairness: 0.012\n",
      "------------------------------ Step 4 - Long-term Fair Model ------------------------------\n",
      "Acc: 70.8%\n",
      "Short Fairness: 0.010\n",
      "Long fairness: 0.004\n",
      "------------------------------ Step 5 - Long-term Fair Model ------------------------------\n",
      "Acc: 69.0%\n",
      "Short Fairness: 0.010\n",
      "Long fairness: 0.006\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, Xs_te, Ys_te = gen_multi_step_profiles(fm_loaded, agent_test, steps=5)\n",
    "OYs_te = generate_y_from_bank(s_test, Xs_te, bank)\n",
    "compute_statistics(s_test, Xs_te, Ys_te, fm_loaded, OYs=OYs_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e7595",
   "metadata": {},
   "source": [
    "### Simulation based on trained param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f4e1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db114cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = Bank()\n",
    "agent_train = Agent(n_samples=4000, protect_ratio=0.5, eps=0.5, base=[0.2, 1.0], seed=2026)\n",
    "agent_test = Agent(n_samples=1000, protect_ratio=0.5, eps=0.5, base=[0.2, 1.0], seed=2027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f416126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ../src/simulation_results_neighbors.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate data via run_simulation() and save a full panel CSV (includes neighbor decision vector D1..D10)\n",
    "steps = 5\n",
    "\n",
    "# run_simulation returns: s, adj, edges, Xs, Ys, Ds, Ps, Os, Us, As\n",
    "s, adj, edges, Xs, Ys, Ds, Ps, Os, Us, As = run_simulation(\n",
    "    decision_model=fm_loaded,\n",
    "    repayment_model=bank,\n",
    "    agent=agent_train,\n",
    "    steps=steps,\n",
    "    enforce_demographic_mixing=True,\n",
    "    k_same=8,\n",
    "    k_other=2,\n",
    "    directed=False,\n",
    "    graph_seed=2026,\n",
    "    seed=2026,\n",
    "    decision_coef=0.8,\n",
    "    repayment_coef=0.8,\n",
    " )\n",
    "\n",
    "out_path = \"../src/simulation_results_neighbors.csv\"\n",
    "save_agent_panel_csv(\n",
    "    out_path,\n",
    "    s=s,\n",
    "    Xs=Xs,\n",
    "    adj=adj,\n",
    "    Ds=Ds,\n",
    "    Ys=Ys,\n",
    "    Ps=Ps,\n",
    "    Us=Us,\n",
    "    As=As,\n",
    "    Os=Os,\n",
    "    t0=0,\n",
    "    neighbor_k=10,\n",
    " )\n",
    "\n",
    "print(\"Wrote:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f816f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Step 1 - Long-term Fair Model ------------------------------\n",
      "Acc: 71.2%\n",
      "Short Fairness: 0.020\n",
      "Long fairness: 0.004\n",
      "------------------------------ Step 2 - Long-term Fair Model ------------------------------\n",
      "Acc: 69.5%\n",
      "Short Fairness: 0.020\n",
      "Long fairness: 0.014\n",
      "------------------------------ Step 3 - Long-term Fair Model ------------------------------\n",
      "Acc: 69.8%\n",
      "Short Fairness: 0.018\n",
      "Long fairness: 0.027\n",
      "------------------------------ Step 4 - Long-term Fair Model ------------------------------\n",
      "Acc: 68.3%\n",
      "Short Fairness: 0.019\n",
      "Long fairness: 0.161\n",
      "------------------------------ Step 5 - Long-term Fair Model ------------------------------\n",
      "Acc: 68.0%\n",
      "Short Fairness: 0.019\n",
      "Long fairness: 0.594\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compute_statistics(s, Xs, Ds, fm_loaded, OYs=Ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
